{"captainVersion":4,"services":{"$$cap_appname":{"restart":"on-failure:5","environment":{"LITELLM_MASTER_KEY":"$$cap_master_key","OPENAI_API_KEY":"$$cap_openai_api_key","OPENAI_ORGANIZATION":"$$cap_openai_organization","ANTHROPIC_API_KEY":"$$cap_anthropic_api_key","MISTRAL_API_KEY":"$$cap_mistral_api_key","GEMINI_API_KEY":"$$cap_gemini_api_key","GOOGLE_APPLICATION_CREDENTIALS":"$$cap_google_application_credentials","HUGGINGFACE_API_KEY":"$$cap_huggingface_api_key","HUGGINGFACE_API_BASE":"$$cap_huggingface_api_base","GROQ_API_KEY":"$$cap_groq_api_key","COHERE_API_KEY":"$$cap_cohere_api_key","PERPLEXITYAI_API_KEY":"$$cap_perplexityai_api_key","SLACK_WEBHOOK_URL":"$$cap_slack_webhook_url","LITELLM_LOG":"$$cap_litellm_log_level","NO_DOCS":"$$cap_litellm_no_docs","DATABASE_URL":"$$cap_database_url","REDIS_HOST":"$$cap_redis_host","REDIS_PORT":"$$cap_redis_port","REDIS_PASSWORD":"$$cap_redis_password"},"volumes":["$$cap_appname-data:/data"],"caproverExtra":{"dockerfileLines":["FROM ghcr.io/berriai/litellm:main-latest","RUN mkdir -p /data && chmod -R +wr /data","RUN test -f /data/config.yaml || \\\n    echo -e \"model_list:\\n - model_name: gpt-3.5-turbo ### RECEIVED MODEL NAME ###\\n   litellm_params:\\n     model: \\\"gpt-3.5-turbo\\\"\\n     api_key: \\$\\$OPENAI_API_KEY\\n   model_info:\\n     mode: completion\\nlitellm_settings:\\n   set_verbose: True\\nrouter_settings:\\n   routing_strategy: usage-based-routing-v2\\ngeneral_settings:\\n   alerting: []\" > /data/config.yaml && \\\n    { [ -n \"$DATABASE_URL\" ] && yq -i '.general_settings.database_url = strenv(DATABASE_URL)' /data/config.yaml || true; } && \\\n    { [ -n \"$REDIS_HOST\" ] && yq -i '.router_settings.redis_host = strenv(REDIS_HOST)' /data/config.yaml || true; } && \\\n    { [ -n \"$REDIS_PORT\" ] && yq -i '.router_settings.redis_port = env(REDIS_PORT)' /data/config.yaml || true; } && \\\n    { [ -n \"$REDIS_PASSWORD\" ] && yq -i '.router_settings.redis_password = strenv(REDIS_PASSWORD)' /data/config.yaml || true; }\n","CMD [\"--port\", \"4000\", \"--config\", \"/data/config.yaml\"]"],"containerHttpPort":4000}}},"caproverOneClickApp":{"variables":[{"id":"$$cap_litellm_log_level","label":"LiteLLM Log Level","description":"The log level for LiteLLM. (enum: INFO, DEBUG, NONE)","defaultValue":"INFO"},{"id":"$$cap_litellm_no_docs","label":"LiteLLM No Docs","description":"Disable the Swagger documentation for LiteLLM. (enum: true, false)","defaultValue":false},{"id":"$$cap_database_url","label":"Database URL","description":"The database URL for LiteLLM. Optional. Only use this if you want to use a database. (postgres or dynamodb)"},{"id":"$$cap_redis_host","label":"Redis Host","description":"The Redis host for LiteLLM. Optional. Only use this if you want to use Redis."},{"id":"$$cap_redis_port","label":"Redis Port","description":"The Redis port for LiteLLM. Optional. Only use this if you want to use Redis."},{"id":"$$cap_redis_password","label":"Redis Password","description":"The Redis password for LiteLLM. Optional. Only use this if you want to use Redis."},{"id":"$$cap_master_key","label":"LiteLLM Master Key","description":"The master key for LiteLLM. Optional. Only use this if you to require all calls to contain this key. (e.g. Authorization: Bearer sk-1234)"},{"id":"$$cap_slack_webhook_url","label":"Slack Webhook URL","description":"The webhook URL for Slack. Get from https://api.slack.com/messaging/webhooks"},{"id":"$$cap_openai_api_key","label":"OpenAI API Key","description":"The API key for OpenAI. Get from https://platform.openai.com/"},{"id":"$$cap_openai_organization","label":"OpenAI Organization","description":"The organization ID for OpenAI."},{"id":"$$cap_anthropic_api_key","label":"Anthropic API Key","description":"The API key for Anthropic service. Get from https://console.anthropic.com/settings/keys"},{"id":"$$cap_mistral_api_key","label":"Mistral API Key","description":"The API key for Mistral service. Get from https://console.mistral.ai/api-keys/"},{"id":"$$cap_gemini_api_key","label":"Gemini API Key","description":"The API key for Gemini service. Get from https://console.cloud.google.com/"},{"id":"$$cap_google_application_credentials","label":"Google Application Credentials","description":"The path to the Google application credentials JSON file. Get from https://console.cloud.google.com/"},{"id":"$$cap_huggingface_api_key","label":"Hugging Face API Key","description":"The API key for Hugging Face service. Get from https://huggingface.co/"},{"id":"$$cap_huggingface_api_base","label":"Hugging Face API Base URL","description":"The base URL for Hugging Face API. (e.g., https://api-inference.huggingface.co/models)"},{"id":"$$cap_groq_api_key","label":"Groq API Key","description":"The API key for Groq service."},{"id":"$$cap_cohere_api_key","label":"Cohere API Key","description":"The API key for Cohere service. Get from https://dashboard.cohere.ai/"},{"id":"$$cap_perplexityai_api_key","label":"Perplexity AI API Key","description":"The API key for Perplexity AI service."}],"displayName":"LiteLLM (Standalone) - LLM Proxy Server","isOfficial":true,"instructions":{"start":"LiteLLM is a lightweight, scalable, and secure API proxy server for LLMs.\n\nBefore installing the LiteLLM app, please ensure you have the following:\n\n* API keys for the AI providers you want to use (e.g., OpenAI, Hugging Face, Azure, etc.).\n* A master key for securing your LiteLLM instance.\n* Credentials (username and password) for accessing the LiteLLM web interface.\n\nDuring the installation process, you will be asked to provide the following information:\n\n* LiteLLM master key for encryption.\n* Username and password for the LiteLLM web interface.\n* API keys and configurations for the AI providers you want to use.\n\nPlease have this information ready before proceeding with the installation.\n\nOnce you have provided the necessary information and the app is successfully deployed you can access the LiteLLM web interface and API using the URLs provided in the post-installation instructions.\n\nIf you encounter any issues during the installation or have any questions, please refer to the LiteLLM documentation: https://docs.litellm.ai/docs/","end":"LiteLLM has been successfully deployed!\n\n* UI not accessible: The UI requires a working database connection. This standalone version does not have a database dependency. You can still use the API endpoints directly.\n\nThe API Swagger docs is available at the root:\nhttp://$$cap_appname.$$cap_root_domain/"},"documentation":"Taken from https://docs.litellm.ai/docs/ Official Website is https://litellm.ai/","description":"[24/04/26 13h15] LiteLLM is a lightweight, scalable, and secure API proxy server for AI providers. This standalone version does not require any external database dependencies."}}
