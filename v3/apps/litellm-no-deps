{"captainVersion":2,"dockerCompose":{"services":{"$$cap_appname":{"restart":"unless-stopped","environment":{"LITELLM_MASTER_KEY":"$$cap_master_key","UI_USERNAME":"$$cap_ui_username","UI_PASSWORD":"$$cap_ui_password","OPENAI_API_KEY":"$$cap_openai_api_key","OPENAI_ORGANIZATION":"$$cap_openai_organization","GOOGLE_APPLICATION_CREDENTIALS":"$$cap_google_application_credentials","GEMINI_API_KEY":"$$cap_gemini_api_key","MISTRAL_API_KEY":"$$cap_mistral_api_key","ANTHROPIC_API_KEY":"$$cap_anthropic_api_key","COHERE_API_KEY":"$$cap_cohere_api_key","HUGGINGFACE_API_KEY":"$$cap_huggingface_api_key","HUGGINGFACE_API_BASE":"$$cap_huggingface_api_base","PERPLEXITYAI_API_KEY":"$$cap_perplexityai_api_key","GROQ_API_KEY":"$$cap_groq_api_key"},"volumes":["$$cap_appname-data:/data"],"containerHttpPort":4000,"dockerfileLines":["FROM ghcr.io/berriai/litellm:main-latest","CMD [\"litellm\", \"--port\", \"4000\", \"--config\", \"/data/config.yaml\"]"]}}},"variables":[{"id":"$$cap_master_key","label":"LiteLLM Master Key","description":"The master key for LiteLLM.","type":"text","defaultValue":"$$cap_gen_random_hex(20)"},{"id":"$$cap_ui_username","label":"UI Username","defaultValue":"litellm","description":"The username for accessing the LiteLLM web interface.","type":"text"},{"id":"$$cap_ui_password","label":"UI Password","description":"The password for accessing the LiteLLM web interface.","defaultValue":null},{"id":"$$cap_litellm_config","label":"LiteLLM Config","description":"The configuration file contents for LiteLLM.","type":"text","defaultValue":null},{"id":"$$cap_openai_api_key","label":"OpenAI API Key","description":"The API key for OpenAI. Get from https://platform.openai.com/"},{"id":"$$cap_openai_organization","label":"OpenAI Organization","description":"The organization ID for OpenAI."},{"id":"$$cap_google_application_credentials","label":"Google Application Credentials","description":"The path to the Google application credentials JSON file. Get from https://console.cloud.google.com/"},{"id":"$$cap_gemini_api_key","label":"Gemini API Key","description":"The API key for Gemini service. Get from https://console.cloud.google.com/"},{"id":"$$cap_mistral_api_key","label":"Mistral API Key","description":"The API key for Mistral service. Get from https://console.mistral.ai/api-keys/"},{"id":"$$cap_anthropic_api_key","label":"Anthropic API Key","description":"The API key for Anthropic service. Get from https://console.anthropic.com/settings/keys"},{"id":"$$cap_cohere_api_key","label":"Cohere API Key","description":"The API key for Cohere service. Get from https://dashboard.cohere.ai/"},{"id":"$$cap_huggingface_api_key","label":"Hugging Face API Key","description":"The API key for Hugging Face service. Get from https://huggingface.co/"},{"id":"$$cap_huggingface_api_base","label":"Hugging Face API Base URL","description":"The base URL for Hugging Face API. (e.g., https://api-inference.huggingface.co/models)"},{"id":"$$cap_perplexityai_api_key","label":"Perplexity AI API Key","description":"The API key for Perplexity AI service."},{"id":"$$cap_groq_api_key","label":"Groq API Key","description":"The API key for Groq service."}],"instructions":{"start":"LiteLLM is a lightweight, scalable, and secure API proxy server for LLMs.\n\nBefore installing the LiteLLM app, please ensure you have the following:\n\n* API keys for the AI providers you want to use (e.g., OpenAI, Hugging Face, Azure, etc.).\n* A master key for securing your LiteLLM instance.\n* Credentials (username and password) for accessing the LiteLLM web interface.\n\nDuring the installation process, you will be asked to provide the following information:\n\n* LiteLLM master key for encryption.\n* Username and password for the LiteLLM web interface.\n* API keys and configurations for the AI providers you want to use.\n\nPlease have this information ready before proceeding with the installation.\n\nOnce you have provided the necessary information and the app is successfully deployed, you can access the LiteLLM web interface and API using the URLs provided in the post-installation instructions.\n\nIf you encounter any issues during the installation or have any questions, please refer to the LiteLLM documentation: https://docs.litellm.ai/docs/","end":"LiteLLM has been successfully deployed!\n\nTo access the LiteLLM web interface, visit:\nhttp://$$cap_appname.$$cap_root_domain/ui\n\nThe API Swagger docs is available at the root:\nhttp://$$cap_appname.$$cap_root_domain/"},"displayName":"LiteLLM (Standalone) - LLM Proxy Server","isOfficial":true,"description":"[24/04/26 9h15] LiteLLM is a lightweight, scalable, and secure API proxy server for AI providers. This standalone version does not require any external database dependencies.","documentation":"Taken from https://docs.litellm.ai/docs/ Official Website is https://litellm.ai/"}
