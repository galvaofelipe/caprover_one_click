{"captainVersion":2,"dockerCompose":{"services":{"$$cap_appname":{"restart":"on-failure:5","environment":{"DATABASE_URL":"$$cap_database_url","UI_USERNAME":"$$cap_ui_username","UI_PASSWORD":"$$cap_ui_password","LITELLM_LOG":"$$cap_litellm_log_level","DEBUG":"$$cap_litellm_debug","OPENAI_API_KEY":"$$cap_openai_api_key","OPENAI_ORGANIZATION":"$$cap_openai_organization","ANTHROPIC_API_KEY":"$$cap_anthropic_api_key","MISTRAL_API_KEY":"$$cap_mistral_api_key","GEMINI_API_KEY":"$$cap_gemini_api_key","GROQ_API_KEY":"$$cap_groq_api_key","COHERE_API_KEY":"$$cap_cohere_api_key"},"volumes":["$$cap_appname-data:/data"],"containerHttpPort":4000,"dockerfileLines":["FROM ghcr.io/berriai/litellm:main-latest","RUN mkdir -p /data && chmod -R +wr /data","RUN cat <<EOF > /data/config.yaml\nmodel_list:\n  - model_name: gpt-3.5-turbo\n    litellm_params:\n      model: \"gpt-3.5-turbo\"\n      api_key: \"os.environ/OPENAI_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: gpt-4-turbo\n    litellm_params:\n      model: \"gpt-4-turbo\"\n      api_key: \"os.environ/OPENAI_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: whisper\n    litellm_params:\n      model: \"whisper-1\"\n      api_key: \"os.environ/OPENAI_API_KEY\"\n    model_info:\n      mode: audio_transcription\n  - model_name: dall-e-3\n    litellm_params:\n      model: \"dall-e-3\"\n      api_key: \"os.environ/OPENAI_API_KEY\"\n    model_info:\n      mode: image_generation\n  - model_name: text-embedding-3\n    litellm_params:\n      model: \"text-embedding-3-small\"\n      api_key: \"os.environ/OPENAI_API_KEY\"\n    model_info:\n      mode: embedding\n  - model_name: claude-3-opus\n    litellm_params:\n      model: \"claude-3-opus-20240229\"\n      api_key: \"os.environ/ANTHROPIC_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: claude-3-sonnet\n    litellm_params:\n      model: \"claude-3-sonnet-20240229\"\n      api_key: \"os.environ/ANTHROPIC_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: claude-3-haiku\n    litellm_params:\n      model: \"claude-3-haiku-20240307\"\n      api_key: \"os.environ/ANTHROPIC_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: mistral-large\n    litellm_params:\n      model: \"mistral-large-latest\"\n      api_key: \"os.environ/MISTRAL_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: mistral-medium\n    litellm_params:\n      model: \"mistral-medium-latest\"\n      api_key: \"os.environ/MISTRAL_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: llama3-8b\n    litellm_params:\n      model: \"groq/llama3-8b-8192\"\n      api_key: \"os.environ/GROQ_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: llama3-70b\n    litellm_params:\n      model: \"groq/llama3-70b-8192\"\n      api_key: \"os.environ/GROQ_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: mixtral-8x7b\n    litellm_params:\n      model: \"groq/mixtral-8x7b-32768\"\n      api_key: \"os.environ/GROQ_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: command-r\n    litellm_params:\n      model: \"cohere/command-r\"\n      api_key: \"os.environ/COHERE_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: command-r-plus\n    litellm_params:\n      model: \"cohere/command-r-plus\"\n      api_key: \"os.environ/COHERE_API_KEY\"\n    model_info:\n      mode: chat\n  - model_name: gemini-1.5-pro\n    litellm_params:\n      model: \"groq/gemini-1.5-pro-latest\"\n      api_key: \"os.environ/GEMINI_API_KEY\"\n    model_info:\n      mode: chat\ngeneral_settings:\n  alerting: []\n  alert_types: []\n  database_url: \"os.environ/DATABASE_URL\"\nlitellm_settings:\n  set_verbose: True\nrouter_settings:\n  timeout: 60\n  max_retries: 3\nEOF","CMD [\"--port\", \"4000\", \"--config\", \"/data/config.yaml\"]"]}}},"variables":[{"id":"$$cap_database_url","label":"Database URL","description":"Optional. Required for UI access. Postgres or DynamoDB Connection String."},{"id":"$$cap_ui_username","label":"UI Username","defaultValue":"litellm","description":"Username for UI access. Only used if database URL is provided."},{"id":"$$cap_ui_password","label":"UI Password","description":"Password for UI access. Only used if database URL is provided."},{"id":"$$cap_litellm_log_level","label":"Log Level","description":"LiteLLM log level. (enum: INFO, DEBUG, NONE)","defaultValue":"INFO"},{"id":"$$cap_litellm_debug","label":"Debug Mode","description":"Enable debug mode. (enum: true, false)","defaultValue":false},{"id":"$$cap_openai_api_key","label":"OpenAI API Key","description":"Get from https://platform.openai.com/"},{"id":"$$cap_anthropic_api_key","label":"Anthropic API Key","description":"Get from https://console.anthropic.com/settings/keys"},{"id":"$$cap_mistral_api_key","label":"Mistral API Key","description":"Get from https://console.mistral.ai/api-keys/"},{"id":"$$cap_gemini_api_key","label":"Gemini API Key","description":"Get from https://console.cloud.google.com/apis/credentials"},{"id":"$$cap_groq_api_key","label":"Groq API Key","description":"Get from https://groq.com/"},{"id":"$$cap_cohere_api_key","label":"Cohere API Key","description":"Get from https://dashboard.cohere.ai/"}],"instructions":{"start":"Requirements:\n- Username and password for UI access (if using database)\n- API keys for desired AI providers\n\nProvide the required information during installation.\n\nSee https://docs.litellm.ai/docs/ for more details.","end":"LiteLLM deployed successfully!\n\n- UI available at http://$$cap_appname.$$cap_root_domain/ui (if database URL provided)\n- API docs available at http://$$cap_appname.$$cap_root_domain/\n\nSee https://docs.litellm.ai/docs/ for more information."},"displayName":"LiteLLM (Standalone) - LLM Proxy Server","isOfficial":true,"description":"[2024/04/26 - 18h57] LiteLLM - API proxy server for AI providers. Standalone version, no database required unless using UI.","documentation":"https://docs.litellm.ai/docs/"}
