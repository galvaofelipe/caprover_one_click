{"captainVersion":2,"dockerCompose":{"services":{"$$cap_appname":{"restart":"on-failure:5","environment":{"DATABASE_URL":"$$cap_database_url","UI_USERNAME":"$$cap_ui_username","UI_PASSWORD":"$$cap_ui_password","LITELLM_LOG":"$$cap_litellm_log_level","DEBUG":"$$cap_litellm_debug","OPENAI_API_KEY":"$$cap_openai_api_key","OPENAI_ORGANIZATION":"$$cap_openai_organization","ANTHROPIC_API_KEY":"$$cap_anthropic_api_key","MISTRAL_API_KEY":"$$cap_mistral_api_key","GEMINI_API_KEY":"$$cap_gemini_api_key","GROQ_API_KEY":"$$cap_groq_api_key","COHERE_API_KEY":"$$cap_cohere_api_key"},"volumes":["$$cap_appname-data:/data"],"containerHttpPort":4000,"dockerfileLines":["FROM ghcr.io/berriai/litellm:main-latest","RUN mkdir -p /data && chmod -R +wr /data","RUN test - f /data/config.yaml || touch /data/config.yaml","RUN [ -z \"$(yq eval '.model_list' /data/config.yaml)\" ] && \\\n  yq eval '.model_list = [ \\\n  { model_name: \"gpt-3.5-turbo\", litellm_params: { model: \"gpt-3.5-turbo\", api_key: \"os.environ/OPENAI_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"gpt-4-turbo\", litellm_params: { model: \"gpt-4-turbo\", api_key: \"os.environ/OPENAI_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"whisper\", litellm_params: { model: \"whisper-1\", api_key: os.environ/OPENAI_API_KEY }, model_info: { mode: audio_transcription } }, \\\n  { model_name: \"dall-e-3\", litellm_params: { model: \"dall-e-3\", api_key: os.environ/OPENAI_API_KEY }, model_info: { mode: image_generation } }, \\\n  { model_name: \"text-embedding-3\", litellm_params: { model: \"text-embedding-3-small\", api_key: os.environ/OPENAI_API_KEY }, model_info: { mode: embedding } }, \\\n  { model_name: \"claude-3-opus\", litellm_params: { model: \"claude-3-opus-20240229\", api_key: \"os.environ/ANTHROPIC_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"claude-3-sonnet\", litellm_params: { model: \"claude-3-sonnet-20240229\", api_key: \"os.environ/ANTHROPIC_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"claude-3-haiku\", litellm_params: { model: \"claude-3-haiku-20240307\", api_key: \"os.environ/ANTHROPIC_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"mistral-large\", litellm_params: { model: \"mistral-large-latest\", api_key: \"os.environ/MISTRAL_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"mistral-medium\", litellm_params: { model: \"mistral-medium-latest\", api_key: \"os.environ/MISTRAL_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"llama3-8b\", litellm_params: { model: \"llama3-8b-8192\", api_key: \"os.environ/GROQ_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"llama3-70b\", litellm_params: { model: \"llama3-70b-8192\", api_key: \"os.environ/GROQ_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"mixtral-8x7b\", litellm_params: { model: \"mixtral-8x7b-32768\", api_key: \"os.environ/GROQ_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"command-r\", litellm_params: { model: \"command-r\", api_key: \"os.environ/COHERE_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"command-r-plus\", litellm_params: { model: \"command-r-plus\", api_key: \"os.environ/COHERE_API_KEY\" }, model_info: { mode: chat } }, \\\n  { model_name: \"gemini-1.5-pro\", litellm_params: { model: \"gemini-1.5-pro-latest\", api_key: \"os.environ/GEMINI_API_KEY\" }, model_info: { mode: chat } } \\\n  ]' /data/config.yaml > /data/config.yaml\n","RUN [ -z \"$(yq eval '.general_settings' /data/config.yaml)\" ] && \\\n  yq eval '.general_settings = { alerting: [], alert_types: [], database_url: \"os.environ/DATABASE_URL\" }' /data/config.yaml > /data/config.yaml\n","RUN [ -z \"$(yq eval '.litellm_settings' /data/config.yaml)\" ] && \\\n  yq eval '.litellm_settings = { set_verbose: true }' /data/config.yaml > /data/config.yaml\n","RUN [ -z \"$(yq eval '.router_settings' /data/config.yaml)\" ] && \\\n  yq eval '.router_settings = { timeout: 60, max_retries: 3 }' /data/config.yaml > /data/config.yaml\n","CMD [\"--port\", \"4000\", \"--config\", \"/data/config.yaml\"]"]}}},"variables":[{"id":"$$cap_database_url","label":"Database URL","description":"Optional. Required for UI access. Postgres or DynamoDB Connection String."},{"id":"$$cap_ui_username","label":"UI Username","defaultValue":"litellm","description":"Username for UI access. Only used if database URL is provided."},{"id":"$$cap_ui_password","label":"UI Password","description":"Password for UI access. Only used if database URL is provided."},{"id":"$$cap_litellm_log_level","label":"Log Level","description":"LiteLLM log level. (enum: INFO, DEBUG, NONE)","defaultValue":"INFO"},{"id":"$$cap_litellm_debug","label":"Debug Mode","description":"Enable debug mode. (enum: true, false)","defaultValue":false},{"id":"$$cap_openai_api_key","label":"OpenAI API Key","description":"Get from https://platform.openai.com/"},{"id":"$$cap_anthropic_api_key","label":"Anthropic API Key","description":"Get from https://console.anthropic.com/settings/keys"},{"id":"$$cap_mistral_api_key","label":"Mistral API Key","description":"Get from https://console.mistral.ai/api-keys/"},{"id":"$$cap_gemini_api_key","label":"Gemini API Key","description":"Get from https://console.cloud.google.com/apis/credentials"},{"id":"$$cap_groq_api_key","label":"Groq API Key","description":"Get from https://groq.com/"},{"id":"$$cap_cohere_api_key","label":"Cohere API Key","description":"Get from https://dashboard.cohere.ai/"}],"instructions":{"start":"Requirements:\n- Username and password for UI access (if using database)\n- API keys for desired AI providers\n\nProvide the required information during installation.\n\nSee https://docs.litellm.ai/docs/ for more details.","end":"LiteLLM deployed successfully!\n\n- UI available at http://$$cap_appname.$$cap_root_domain/ui (if database URL provided)\n- API docs available at http://$$cap_appname.$$cap_root_domain/\n\nSee https://docs.litellm.ai/docs/ for more information."},"displayName":"LiteLLM (Standalone) - LLM Proxy Server","isOfficial":true,"description":"[2024/04/26 - 18h20] LiteLLM - API proxy server for AI providers. Standalone version, no database required unless using UI.","documentation":"https://docs.litellm.ai/docs/"}
