captainVersion: 4
services:
    $$cap_appname:
        restart: on-failure:5
        environment:
            DATABASE_URL: $$cap_database_url
            UI_USERNAME: $$cap_ui_username
            UI_PASSWORD: $$cap_ui_password
            LITELLM_LOG: $$cap_litellm_log_level
            DEBUG: $$cap_litellm_debug
            OPENAI_API_KEY: $$cap_openai_api_key
            OPENAI_ORGANIZATION: $$cap_openai_organization
            ANTHROPIC_API_KEY: $$cap_anthropic_api_key
            MISTRAL_API_KEY: $$cap_mistral_api_key
            GEMINI_API_KEY: $$cap_gemini_api_key
            GROQ_API_KEY: $$cap_groq_api_key
            COHERE_API_KEY: $$cap_cohere_api_key
        volumes:
            - '$$cap_appname-data:/data'
        # image: ghcr.io/berriai/litellm:main-latest - use the dockerfileLines instead
        caproverExtra:
            dockerfileLines:
                - 'FROM ghcr.io/berriai/litellm:main-latest'
                - 'RUN mkdir -p /data && chmod -R +wr /data'
                - |-
                    RUN cat <<EOF > | sed 's/^                      //' /data/config.yaml
                    model_list:
                      - model_name: gpt-3.5-turbo
                        litellm_params:
                          model: "gpt-3.5-turbo"
                          api_key: "os.environ/OPENAI_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: gpt-4-turbo
                        litellm_params:
                          model: "gpt-4-turbo"
                          api_key: "os.environ/OPENAI_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: whisper
                        litellm_params:
                          model: "whisper-1"
                          api_key: "os.environ/OPENAI_API_KEY"
                        model_info:
                          mode: audio_transcription
                      - model_name: dall-e-3
                        litellm_params:
                          model: "dall-e-3"
                          api_key: "os.environ/OPENAI_API_KEY"
                        model_info:
                          mode: image_generation
                      - model_name: text-embedding-3
                        litellm_params:
                          model: "text-embedding-3-small"
                          api_key: "os.environ/OPENAI_API_KEY"
                        model_info:
                          mode: embedding
                      - model_name: claude-3-opus
                        litellm_params:
                          model: "claude-3-opus-20240229"
                          api_key: "os.environ/ANTHROPIC_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: claude-3-sonnet
                        litellm_params:
                          model: "claude-3-sonnet-20240229"
                          api_key: "os.environ/ANTHROPIC_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: claude-3-haiku
                        litellm_params:
                          model: "claude-3-haiku-20240307"
                          api_key: "os.environ/ANTHROPIC_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: mistral-large
                        litellm_params:
                          model: "mistral-large-latest"
                          api_key: "os.environ/MISTRAL_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: mistral-medium
                        litellm_params:
                          model: "mistral-medium-latest"
                          api_key: "os.environ/MISTRAL_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: llama3-8b
                        litellm_params:
                          model: "groq/llama3-8b-8192"
                          api_key: "os.environ/GROQ_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: llama3-70b
                        litellm_params:
                          model: "groq/llama3-70b-8192"
                          api_key: "os.environ/GROQ_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: mixtral-8x7b
                        litellm_params:
                          model: "groq/mixtral-8x7b-32768"
                          api_key: "os.environ/GROQ_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: command-r
                        litellm_params:
                          model: "cohere/command-r"
                          api_key: "os.environ/COHERE_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: command-r-plus
                        litellm_params:
                          model: "cohere/command-r-plus"
                          api_key: "os.environ/COHERE_API_KEY"
                        model_info:
                          mode: chat
                      - model_name: gemini-1.5-pro
                        litellm_params:
                          model: "groq/gemini-1.5-pro-latest"
                          api_key: "os.environ/GEMINI_API_KEY"
                        model_info:
                          mode: chat
                    general_settings:
                      alerting: []
                      alert_types: []
                      database_url: "os.environ/DATABASE_URL"
                    litellm_settings:
                      set_verbose: True
                    router_settings:
                      timeout: 60
                      max_retries: 3
                    EOF
                - 'CMD ["--port", "4000", "--config", "/data/config.yaml"]'
            containerHttpPort: 4000
caproverOneClickApp:
    variables:
        - id: $$cap_database_url
          label: Database URL
          description: >-
              Optional. Required for UI access. Postgres or DynamoDB Connection String.
        - id: $$cap_ui_username
          label: UI Username
          defaultValue: litellm
          description: Username for UI access. Only used if database URL is provided.
        - id: $$cap_ui_password
          label: UI Password
          description: Password for UI access. Only used if database URL is provided.
        - id: $$cap_litellm_log_level
          label: Log Level
          description: |-
              LiteLLM log level. (enum: INFO, DEBUG, NONE)
          defaultValue: INFO
        - id: $$cap_litellm_debug
          label: Debug Mode
          description: |-
              Enable debug mode. (enum: true, false)
          defaultValue: false
        # Integrations
        - id: $$cap_openai_api_key
          label: OpenAI API Key
          description: Get from https://platform.openai.com/
        - id: $$cap_anthropic_api_key
          label: Anthropic API Key
          description: Get from https://console.anthropic.com/settings/keys
        - id: $$cap_mistral_api_key
          label: Mistral API Key
          description: Get from https://console.mistral.ai/api-keys/
        - id: $$cap_gemini_api_key
          label: Gemini API Key
          description: Get from https://console.cloud.google.com/apis/credentials
        - id: $$cap_groq_api_key
          label: Groq API Key
          description: Get from https://groq.com/
        - id: $$cap_cohere_api_key
          label: Cohere API Key
          description: Get from https://dashboard.cohere.ai/
    displayName: LiteLLM (Standalone) - LLM Proxy Server
    isOfficial: True
    instructions:
        start: |-
            Requirements:
            - Username and password for UI access (if using database)
            - API keys for desired AI providers

            Provide the required information during installation.

            See https://docs.litellm.ai/docs/ for more details.
        end: |-
            LiteLLM deployed successfully!

            - UI available at http://$$cap_appname.$$cap_root_domain/ui (if database URL provided)
            - API docs available at http://$$cap_appname.$$cap_root_domain/

            See https://docs.litellm.ai/docs/ for more information.
    documentation: https://docs.litellm.ai/docs/
    description: |-
        [2024/04/26 - 19h10] LiteLLM - API proxy server for AI providers. Standalone version, no database required unless using UI.
